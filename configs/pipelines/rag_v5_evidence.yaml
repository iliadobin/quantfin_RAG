# RAGv5: Evidence validation pipeline configuration

pipeline:
  name: RAGv5_Evidence
  version: "5.0"
  description: "Maximum reliability with evidence validation"

retrieval:
  type: hybrid
  bm25_weight: 0.5
  dense_weight: 0.5
  rrf_k: 60
  top_k: 20
  dense_model: "intfloat/e5-small-v2"

rerank:
  enabled: true
  model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  top_k: 10
  device: cpu

generation:
  model: "deepseek-chat"
  temperature: 0.0
  max_tokens: 2048
  max_context_chunks: 10

guardrails:
  unanswerable_detection: true
  min_retrieval_score: 0.1
  
  evidence_validation:
    enabled: true
    mode: rule_based  # rule_based | llm_based
    min_citation_coverage: 0.5  # 50% of sentences should have citations
    min_confidence_threshold: 0.3

performance:
  expected_latency_ms: 3700
  expected_tokens: 500  # rule_based: ~500, llm_based: ~800

notes: |
  Evidence validation modes:
  
  - rule_based (default, recommended):
    * Fast (~50ms)
    * No additional tokens
    * Checks citation coverage ratio
    * Confidence adjustment based on coverage
  
  - llm_based (optional, more accurate):
    * Slower (~500ms)
    * ~300 additional tokens per query
    * Claim-by-claim verification
    * More accurate but costly
  
  Use rule_based for most queries, llm_based only for critical questions.

